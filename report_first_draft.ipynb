{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "passive-collect",
   "metadata": {},
   "source": [
    "# WiDS 2023 - Codeup Submission\n",
    "## Predict the arithmetic mean of the max and min observed temperature over the next 14 days for specific locations and start dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb1b93",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "Extreme weather events are sweeping the globe and range from heat waves, wildfires and drought to hurricanes, extreme rainfall and flooding. These weather events have multiple impacts on agriculture, energy, transportation, as well as low resource communities and disaster planning in countries across the globe.\n",
    "\n",
    "Accurate long-term forecasts of temperature and precipitation are crucial to help people prepare and adapt to these extreme weather events. Currently, purely physics-based models dominate short-term weather forecasting. But these models have a limited forecast horizon. The availability of meteorological data offers an opportunity for data scientists to improve sub-seasonal forecasts by blending physics-based forecasts with machine learning. Sub-seasonal forecasts for weather and climate conditions (lead-times ranging from 15 to more than 45 days) would help communities and industries adapt to the challenges brought on by climate change.\n",
    "\n",
    "Participants will submit forecasts of temperature and precipitation for one year, competing against the other teams as well as official forecasts from NOAA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-anime",
   "metadata": {},
   "source": [
    "## Project Goals\n",
    "* Determine which columns to use for our data exploration.\n",
    "* Explore to find features that indicate the ```mean_temp```.\n",
    "* Based on the findings predict the ```mean_temp``` for the test_data.\n",
    "* Submit our finidings to the WiDS 2023 competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-insertion",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "following-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import wrangle as w\n",
    "import explore as e\n",
    "import model as m\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-swimming",
   "metadata": {},
   "source": [
    "# Acquire\n",
    "\n",
    "* Data acquired from [Kaggle](https://www.kaggle.com/competitions/widsdatathon2023/data)\n",
    "* It contained 375734 rows and 245 columns before cleaning\n",
    "* Each row represents a specific location on a specific start date\n",
    "* Each column represents a weather/climate measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-steering",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "\n",
    "**Prepare Actions:**\n",
    "* Binned regions (Dry, Temperate, Continental) \n",
    "* Binned elevation ('bottom_low', 'top_low', 'mid', 'high')\n",
    "* Split data into train, validate and test (approx. 60/25/15)\n",
    "* Scaled continuous variables (min/max scaler)\n",
    "* Outliers have not been removed for this iteration of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f308f",
   "metadata": {},
   "source": [
    "## Data Dictionary:\n",
    "### Target\n",
    "| Target | Definition | Data Type | Unit |\n",
    "| :---- | :---- | :---- | :---- |\n",
    "| **mean_temp**| the arithmetic mean | *float64* | celsius |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-plymouth",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "| Feature Name | Definition | Data Type | Unit |\n",
    "| :---- | :---- | :---- | :---- |\n",
    "| region | Köppen-Geigerclimateclassifications | object | specified regions |\n",
    "| elevation | elevation | int64 | meters |\n",
    "| lat| latitude of location (anonymized) | float64 | latitude |\n",
    "| lon | longitude of location (anonymized) | float64 | longitude |\n",
    "| startdate | startdate of the 14 day period | object | dates |\n",
    "| potential_evap| potential evaporation | float64 | mL |\n",
    "| precip| measured precipitation | float64 | mm |\n",
    "| barometric_pressure | pressure | float64 |Hg (inches of mercury) |\n",
    "| all_atmos_precip | precipitable water for entire atmosphere | float64 | mm |\n",
    "| relative humidity | relative humidity | float64 | percent of atmospheric capacity |\n",
    "| sea level pressure | sea level pressure at surface | float64 | hectoPascals (hPa), also called millibars |\n",
    "| geopotential height at 10 millibars | actual height of a pressure surface above mean sea-level | float64 | millibars |\n",
    "| geopotential height at 100 millibars | actual height of a pressure surface above mean sea-level | float64 | millibars |\n",
    "| geopotential height at 500 millibars | actual height of a pressure surface above mean sea-level | float64 | millibars |\n",
    "| geopotential height at 850 millibars | actual height of a pressure surface above mean sea-level | float64 | millibars |\n",
    "| zonal wind at 250 millibars | east-west wind velocity| float64 | meters per second |\n",
    "| zonal wind at 925 millibars | east-west wind velocity | float64 | meters per second|\n",
    "| longitudinal wind at 250 millibars | north-south velocity | float64 | meters per second|\n",
    "| longitudinal wind at 925 millibars | north-south velocity | float64 |meters per second |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pressing-legislation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# acquiring data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_explore_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# prepping data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mget_contest_data(df)\n",
      "File \u001b[0;32m~/codeup-data-science/mirzakhani_shared/wrangle.py:21\u001b[0m, in \u001b[0;36mget_explore_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_explore_data\u001b[39m():\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124;03m''' \u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    This function reads in a csv held in the same repository folder\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data.csv'"
     ]
    }
   ],
   "source": [
    "# acquiring data\n",
    "df = w.get_explore_data()\n",
    "\n",
    "# prepping data\n",
    "df = w.get_contest_data(df)\n",
    "\n",
    "# splitting data into train, validate, and test\n",
    "train, validate, test = w.split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-continuity",
   "metadata": {},
   "source": [
    "## A brief look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-junior",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-paper",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.data_distribution(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-attendance",
   "metadata": {},
   "source": [
    "## Is there a difference in the temperatures in different climateregions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec714443",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.region_viz(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a137d559",
   "metadata": {},
   "source": [
    "## Does elevation impact temperature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e73005",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.elevation_bin_viz(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eaba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.elevation_bin_dist_viz(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.elevation_bin_kruskal_test(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ce319",
   "metadata": {},
   "source": [
    "## Is there a correlation between precipitation and mean_temp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ad96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.precipitation_viz(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eca51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.precip_spearmanr_test(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9957b915",
   "metadata": {},
   "source": [
    "## Is there a correlation between potential evap and mean_temp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.potential_evap_viz(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090234d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.potential_evap_spearmanr_test(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ef37b",
   "metadata": {},
   "source": [
    "## Is there a correlation between mean_temp and geopotential at different heights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69890a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e.geopotential_viz(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-industry",
   "metadata": {},
   "source": [
    "# Exploration Summary\n",
    "\n",
    "* We made the decision to look at the features closest to our target (features with 14d and categorical variables) and explored them.\n",
    "* We saw that all of the continuous variables have a correlation with our target variable. \n",
    "* We looked at our regions and saw that there is a difference in the mean mean_temp in each region.\n",
    "* We binned our elevations, splitting into 4 bins based on quantiles. We saw that there is a differenc in mean mean_temp of each bin.\n",
    "\n",
    "# Features I am moving to modeling with\n",
    "\n",
    "| Feature Name | Definition | Data Type | Unit |\n",
    "| :---- | :---- | :---- | :---- |\n",
    "| region | Köppen-Geigerclimateclassifications | object | specified regions |\n",
    "| elevation | elevation | int64 | meters |\n",
    "| lat| latitude of location (anonymized) | float64 | latitude |\n",
    "| lon | longitude of location (anonymized) | float64 | longitude |\n",
    "| startdate | startdate of the 14 day period | object | dates |\n",
    "| potential_evap| potential evaporation | float64 | mL |\n",
    "| precip| measured precipitation | float64 | mm |\n",
    "| barometric_pressure | pressure | float64 |Hg (inches of mercury) |\n",
    "| all_atmos_precip | precipitable water for entire atmosphere | float64 | mm |\n",
    "| relative humidity | relative humidity | float64 | percent of atmospheric capacity |\n",
    "| sea level pressure | sea level pressure at surface | float64 | hectoPascals (hPa), also called millibars |\n",
    "| geopotential height at 10 millibars | actual height of a pressure surface above mean sea-level | float64 | millibars |\n",
    "| geopotential height at 100 millibars | actual height of a pressure surface above mean sea-level | float64 | millibars |\n",
    "| geopotential height at 500 millibars | actual height of a pressure surface above mean sea-level | float64 | millibars |\n",
    "| geopotential height at 850 millibars | actual height of a pressure surface above mean sea-level | float64 | millibars |\n",
    "| zonal wind at 250 millibars | east-west wind velocity| float64 | meters per second |\n",
    "| zonal wind at 925 millibars | east-west wind velocity | float64 | meters per second|\n",
    "| longitudinal wind at 250 millibars | north-south velocity | float64 | meters per second|\n",
    "| longitudinal wind at 925 millibars | north-south velocity | float64 |meters per second |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7152f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of the features\n",
    "drivers = list(train.columns)\n",
    "#drop startdate and target variable\n",
    "drivers.remove('startdate')\n",
    "drivers.remove('mean_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-halifax",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for modeling\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = m.prep_for_model(train, validate, test, 'mean_temp', drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931f88c",
   "metadata": {},
   "source": [
    "## Mean Baseline RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf07080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show baseline model\n",
    "m.baseline_models(y_train, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-denmark",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.regression_models(X_train, y_train, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-screen",
   "metadata": {},
   "source": [
    "## Best Model on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.best_model(X_train, y_train, X_validate, y_validate, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-wallace",
   "metadata": {},
   "source": [
    "### Modeling Summary\n",
    "\n",
    "* We looked at three different kinds of models.\n",
    "* Quadratic model performed best on both train and validate.\n",
    "* We used that model to predict on test and our RMSE remained at a **1.27**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-initial",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "### Exploration\n",
    "\n",
    "* We saw that all of the continuous variables have a correlation with our target variable. \n",
    "* We looked at our regions and saw that there is a difference in the mean mean_temp in each region.\n",
    "* We binned our elevations, splitting into 4 bins based on quantiles. We saw that there is a differenc in mean mean_temp of each bin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-oriental",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "* We looked at three different kinds of models.\n",
    "* Saw that our quadratic model performed best on both train and validate.\n",
    "* We used that model to predict on test and our RMSE remained at a **1.27**.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "* We can use this model to predict the mean temp for the next 14d.\n",
    "\n",
    "### Next Steps\n",
    "* We want to look into creating a model based on the region.\n",
    "* We want to continue looking at other features in the data set to see if they have correlation with the target variable.\n",
    "* We want to look into other models that might help improve our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
